{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classical Multiclass Neural Network\n",
    "\n",
    "In this notebook, we create a neural network model identical in the architecture with the other Bayesian-based one. Therefore, there are 4 inputs, 3 outputs (categorical) and 2 hidden layers with 5 neurons each. The optimization function is `adam`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependencies\n",
    "import keras\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris, make_blobs\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate random data based on a seed `random_state`, renormalize and create the train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iris = load_iris()\n",
    "# X = iris.data\n",
    "# Y = iris.target\n",
    "X, Y = make_blobs(n_samples=250, centers=3, n_features=4, random_state=0)\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "Y = enc.fit_transform(Y.reshape(-1, 1))\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X.shape[1]\n",
    "classes = Y.shape[1]\n",
    "hidden = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the neural network's model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(hidden, input_dim=features, activation='tanh'))\n",
    "model.add(Dense(hidden, activation='tanh'))\n",
    "model.add(Dense(classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a32db0ac8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=500, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Down below, it can be seen that the accuracy of the model on the test set sits at `100%`. It's the same case for the train set, which means there isn't a case of underfitting/overfitting.\n",
    "\n",
    "In comparison to the other Bayesian-based neural network, the training on the traditional one took much less time (like just for a few seconds), whereas for the other one it took a few minutes. And that's taking into consideration the small size of the dataset.\n",
    "\n",
    "If the dataset were smaller, it could be seen that the traditional neural network would start performing poorly, whereas the Bayesian would get an acceptable accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175/175 [==============================] - 0s 831us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.01498369313776493, 1.0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 384us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.013747863781948885, 1.0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.5",
   "language": "python",
   "name": "python3.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
